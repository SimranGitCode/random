{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgCitGwRxGCa"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy scikit-learn nltk\n",
        "!pip install -q transformers sentence-transformers xgboost scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yolmPjJr92cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "ZsNHU-EKxGwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()\n",
        "\n",
        "df = pd.read_csv(\"labeled_dialogues_groq.csv\")\n",
        "\n",
        "df[\"labels\"] = df[\"labels\"].apply(ast.literal_eval)\n",
        "df[\"text\"] = df[\"dialogue\"].astype(str) + \" \" + df[\"clinical_note\"].astype(str)\n",
        "\n",
        "df[\"has_adverse_event\"] = df[\"labels\"].apply(\n",
        "    lambda x: 0 if \"no_adverse_event\" in x else 1\n",
        ")\n",
        "\n",
        "df[\"labels_clean\"] = df[\"labels\"].apply(\n",
        "    lambda x: [l for l in x if l != \"no_adverse_event\"]\n",
        ")"
      ],
      "metadata": {
        "id": "_zxLLhTJxLNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"text\"]\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_multi = mlb.fit_transform(df[\"labels_clean\"])\n",
        "label_classes = mlb.classes_\n",
        "\n",
        "X_train, X_test, y_bin_train, y_bin_test, y_mul_train, y_mul_test = train_test_split(\n",
        "    X,\n",
        "    df[\"has_adverse_event\"],\n",
        "    y_multi,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"has_adverse_event\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "4seuJMQexVti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1,2),\n",
        "    stop_words=\"english\"\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n"
      ],
      "metadata": {
        "id": "5XgJQLm0xg4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "X_train_bert = bert_model.encode(X_train.tolist(), convert_to_numpy=True)\n",
        "X_test_bert = bert_model.encode(X_test.tolist(), convert_to_numpy=True)\n"
      ],
      "metadata": {
        "id": "fG-x9pIJxkNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=y_bin_train.value_counts()[0] / y_bin_train.value_counts()[1],\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "binary_model.fit(X_train_tfidf, y_bin_train)"
      ],
      "metadata": {
        "id": "EUEdZACcxm-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression (TF-IDF)\n",
        "lr_model = OneVsRestClassifier(\n",
        "    LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
        ")\n",
        "lr_model.fit(X_train_tfidf, y_mul_train)\n",
        "\n",
        "# XGBoost (per label)\n",
        "xgb_models = {}\n",
        "for idx, label in enumerate(label_classes):\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train_tfidf, y_mul_train[:, idx])\n",
        "    xgb_models[label] = model\n",
        "\n",
        "# Logistic Regression (BERT)\n",
        "lr_bert = OneVsRestClassifier(\n",
        "    LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
        ")\n",
        "lr_bert.fit(X_train_bert, y_mul_train)\n"
      ],
      "metadata": {
        "id": "LxICHOq6yFOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_categories_ensemble(text, weights=(0.2, 0.5, 0.3)):\n",
        "    vec_tfidf = tfidf.transform([text])\n",
        "\n",
        "    lr_probs = lr_model.predict_proba(vec_tfidf)[0]\n",
        "    xgb_probs = np.array([\n",
        "        xgb_models[label].predict_proba(vec_tfidf)[0][1]\n",
        "        for label in label_classes\n",
        "    ])\n",
        "\n",
        "    bert_vec = bert_model.encode([text], convert_to_numpy=True)\n",
        "    bert_probs = lr_bert.predict_proba(bert_vec)[0]\n",
        "\n",
        "    final_probs = (\n",
        "        weights[0]*lr_probs +\n",
        "        weights[1]*xgb_probs +\n",
        "        weights[2]*bert_probs\n",
        "    )\n",
        "\n",
        "    return dict(zip(label_classes, final_probs))\n"
      ],
      "metadata": {
        "id": "LRpQHJYOyL3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_thresholds(y_true, y_prob, labels):\n",
        "    thresholds = {}\n",
        "    for i, label in enumerate(labels):\n",
        "        best_f1, best_t = 0, 0.5\n",
        "        for t in np.arange(0.1, 0.91, 0.01):\n",
        "            preds = (y_prob[:, i] >= t).astype(int)\n",
        "            f1 = f1_score(y_true[:, i], preds)\n",
        "            if f1 > best_f1:\n",
        "                best_f1, best_t = f1, t\n",
        "        thresholds[label] = best_t\n",
        "    return thresholds\n",
        "\n",
        "\n",
        "y_val_probs = np.array([\n",
        "    [predict_categories_ensemble(text)[l] for l in label_classes]\n",
        "    for text in X_test\n",
        "])\n",
        "\n",
        "optimal_thresholds = optimize_thresholds(\n",
        "    y_mul_test, y_val_probs, label_classes\n",
        ")"
      ],
      "metadata": {
        "id": "rKdi4RT4yZmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIGH_RISK = {\"emergency\", \"allergic_reaction\", \"medication_error\"}\n",
        "MEDIUM_RISK = {\"infection\", \"symptom_worsening\", \"side_effects\"}\n",
        "\n",
        "for label in label_classes:\n",
        "    if label in HIGH_RISK:\n",
        "        optimal_thresholds[label] = max(0.25, optimal_thresholds[label] - 0.15)\n",
        "    elif label in MEDIUM_RISK:\n",
        "        optimal_thresholds[label] = max(0.35, optimal_thresholds[label] - 0.10)\n",
        "    else:\n",
        "        optimal_thresholds[label] = min(0.65, optimal_thresholds[label] + 0.10)\n"
      ],
      "metadata": {
        "id": "OV7bAQ3QyeUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_thresholds_with_fallback(probs, threshold_map):\n",
        "    active = [l for l, p in probs.items() if p >= threshold_map[l]]\n",
        "    if not active:\n",
        "        active = [max(probs, key=probs.get)]\n",
        "    return active\n"
      ],
      "metadata": {
        "id": "i2igB78EzPTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_adverse_event_pipeline(text):\n",
        "    vec = tfidf.transform([text])\n",
        "    binary_prob = binary_model.predict_proba(vec)[0][1]\n",
        "\n",
        "    if binary_prob < 0.2:\n",
        "        return {\n",
        "            \"predicted_categories\": [\"no_adverse_event\"],\n",
        "            \"risk_level\": \"LOW\",\n",
        "            \"confidence\": round(1 - binary_prob, 3)\n",
        "        }\n",
        "\n",
        "    probs = predict_categories_ensemble(text)\n",
        "    active_labels = apply_thresholds_with_fallback(probs, optimal_thresholds)\n",
        "\n",
        "    if any(l in HIGH_RISK for l in active_labels):\n",
        "        risk = \"HIGH\"\n",
        "    elif any(l in MEDIUM_RISK for l in active_labels):\n",
        "        risk = \"MEDIUM\"\n",
        "    else:\n",
        "        risk = \"LOW\"\n",
        "\n",
        "    return {\n",
        "        \"predicted_categories\": active_labels,\n",
        "        \"risk_level\": risk,\n",
        "        \"confidence\": round(max(probs.values()), 3),\n",
        "        \"category_probabilities\": probs\n",
        "    }\n"
      ],
      "metadata": {
        "id": "f3PN3Oo0zQn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ensemble(X_test, y_test):\n",
        "    preds = []\n",
        "\n",
        "    for text in X_test:\n",
        "        vec = tfidf.transform([text])\n",
        "        binary_prob = binary_model.predict_proba(vec)[0][1]\n",
        "\n",
        "        if binary_prob < 0.2:\n",
        "            preds.append([0]*len(label_classes))\n",
        "        else:\n",
        "            probs = predict_categories_ensemble(text)\n",
        "            labels = apply_thresholds_with_fallback(probs, optimal_thresholds)\n",
        "            preds.append([1 if l in labels else 0 for l in label_classes])\n",
        "\n",
        "    preds = np.array(preds)\n",
        "\n",
        "    print(\"ENSEMBLE MODEL RESULTS (FIXED)\")\n",
        "    print(classification_report(\n",
        "        y_test,\n",
        "        preds,\n",
        "        target_names=label_classes,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "\n",
        "evaluate_ensemble(X_test, y_mul_test)\n"
      ],
      "metadata": {
        "id": "Tr4dtNA0zTxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "SAVE_DIR = \"saved_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "iq1HH4qNzXBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(binary_model, f\"{SAVE_DIR}/binary_model.pkl\")\n",
        "joblib.dump(lr_model, f\"{SAVE_DIR}/lr_tfidf.pkl\")\n",
        "joblib.dump(lr_bert, f\"{SAVE_DIR}/lr_clinical_bert.pkl\")\n",
        "joblib.dump(xgb_models, f\"{SAVE_DIR}/xgb_models.pkl\")\n"
      ],
      "metadata": {
        "id": "pdJUC6xc2hS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(tfidf, f\"{SAVE_DIR}/tfidf.pkl\")\n",
        "joblib.dump(mlb, f\"{SAVE_DIR}/mlb.pkl\")\n",
        "joblib.dump(label_classes, f\"{SAVE_DIR}/label_classes.pkl\")\n",
        "joblib.dump(optimal_thresholds, f\"{SAVE_DIR}/optimal_thresholds.pkl\")"
      ],
      "metadata": {
        "id": "8eWOh9Kb2j3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.save(f\"{SAVE_DIR}/bert_encoder\")\n"
      ],
      "metadata": {
        "id": "7AZVcUUs2l72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pipreqs\n"
      ],
      "metadata": {
        "id": "crOK9UZ62n9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQsRvHTgQ0sy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}